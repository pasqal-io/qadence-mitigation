{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Qadence Mitigation","text":"<p>Qadence Mitigation is a collection of features to enhance Qadence outputs for error mitigation.</p>"},{"location":"#pre-requisites","title":"Pre-requisites","text":"<p>The library uses the following tools:</p> <ul> <li>hatch for managing virtual environment and dependencies</li> <li>pytest for building the unit tests suite</li> <li>black, isort and flake8 for code formatting and linting</li> <li>mypy for static type checking</li> <li>pre-commit for applying linting and formatting automatically before committing new code</li> </ul> <p>We recommend to use <code>pyenv</code> for managing python versions for managing python versions both globally and locally:</p> <pre><code># System-wide install of a python version.\npyenv install 3.10\n\n# Use 3.10 everywhere.\npyenv global 3.10\n\n# Or locally in the current directory.\npyenv local 3.10\n</code></pre>"},{"location":"#install-from-pypi","title":"Install from PyPi","text":"<p><code>qadence-mitigation</code> is available on PyPi through <code>pip</code>.</p> <pre><code>pip install qadence-mitigation\n</code></pre>"},{"location":"#install-from-source","title":"Install from source","text":"<p>All Pasqal quantum libraries require Python &gt;=3.9. For development, the preferred method to install this package is to use <code>hatch</code>. You can install from source by cloning this repository and run:</p> <pre><code>python -m pip install hatch\npython -m hatch -v shell\n\n# execute any script using the library\npython my_script.py\n</code></pre> <p>Alternatively, you can also:</p> <ul> <li>install with <code>pip</code> in development mode by simply running <code>pip install -e .</code>. Notice that in this way   you will install all the dependencies, including extras.</li> <li>install it with <code>conda</code> by simply using <code>pip</code> inside the Conda environment.</li> </ul>"},{"location":"#develop","title":"Develop","text":"<p>When developing the package, the recommended way is to create a virtual environment with <code>hatch</code> as shown above:</p> <pre><code>python -m pip install hatch\npython -m hatch -v shell\n</code></pre> <p>When inside the shell with development dependencies, install first the pre-commit hook: <pre><code>pre-commit install\n</code></pre></p> <p>In this way, you will get automatic linting and formatting every time you commit new code. Do not forget to run the unit test suite by simply running the <code>pytest</code> command.</p> <p>If you do not want to get into the Hatch shell, you can alternatively do the following:</p> <pre><code>python -m pip install hatch\npython -m hatch -v shell\n\n# install the pre-commit\npython -m hatch run pre-commit install\n\n# commit some code\npython -m hatch run git commit -m \"My awesome commit\"\n\n# run the unit tests suite\npython -m hatch run pytest\n</code></pre>"},{"location":"#document","title":"Document","text":"<p>You can improve the documentation of the package by editing this file for the landing page or adding new markdown or Jupyter notebooks to the <code>docs/</code> folder in the root of the project. In order to modify the table of contents, edit the <code>mkdocs.yml</code> file in the root of the project.</p> <p>In order to build and serve the documentation locally, you can use <code>hatch</code> with the right environment:</p> <pre><code>python -m hatch -v run docs:build\npython -m hatch -v run docs:serve\n</code></pre> <p>If you don't want to use <code>hatch</code>, just check into your favorite virtual environment and execute the following commands:</p> <pre><code>python -m pip install -r docs/requirements.txt\nmkdocs build\nmkdocs serve\n</code></pre>"},{"location":"CODE_OF_CONDUCT/","title":"CODE OF CONDUCT","text":"<p>Code of Conduct</p>"},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"CONTRIBUTING/","title":"How to contribute","text":"<p>We're grateful for your interest in participating in qadence-mitigation. Please follow our guidelines to ensure a smooth contribution process.</p>"},{"location":"CONTRIBUTING/#reporting-an-issue-or-proposing-a-feature","title":"Reporting an issue or proposing a feature","text":"<p>Your course of action will depend on your objective, but generally, you should start by creating an issue. If you've discovered a bug or have a feature you'd like to see added to qadence-mitigation, feel free to create an issue on qadence-mitigation GitHub issue tracker. Here are some steps to take:</p> <ol> <li>Quickly search the existing issues using relevant keywords to ensure your issue hasn't been addressed already.</li> <li> <p>If your issue is not listed, create a new one. Try to be as detailed and clear as possible in your description.</p> </li> <li> <p>If you're merely suggesting an improvement or reporting a bug, that's already excellent! We thank you for it. Your issue will be listed and, hopefully, addressed at some point.</p> </li> <li>However, if you're willing to be the one solving the issue, that would be even better! In such instances, you would proceed by preparing a Pull Request.</li> </ol>"},{"location":"CONTRIBUTING/#submitting-a-pull-request","title":"Submitting a pull request","text":"<p>We're excited that you're eager to contribute to qadence-mitigation. To contribute, fork the <code>main</code> branch of qadence repository and once you are satisfied with your feature and all the tests pass create a Pull Request.</p> <p>Here's the process for making a contribution:</p> <p>Click the \"Fork\" button at the upper right corner of the repo page to create a new GitHub repo at <code>https://github.com/USERNAME/qadence-mitigation</code>, where <code>USERNAME</code> is your GitHub ID. Then, <code>cd</code> into the directory where you want to place your new fork and clone it:</p> <pre><code>git clone https://github.com/USERNAME/qadence-mitigation.git\n</code></pre> <p>Next, navigate to your new qadence fork directory and mark the main qadence repository as the <code>upstream</code>:</p> <pre><code>git remote add upstream https://github.com/pasqal-io/qadence-mitigation.git\n</code></pre>"},{"location":"CONTRIBUTING/#setting-up-your-development-environment","title":"Setting up your development environment","text":"<p>We recommended to use <code>hatch</code> for managing environments:</p> <p>To develop within qadence, use: <pre><code>pip install hatch\nhatch -v shell\n</code></pre></p> <p>To run qadence tests, use:</p> <pre><code>hatch -e tests run test\n</code></pre> <p>If you don't want to use <code>hatch</code>, you can use the environment manager of your choice (e.g. Conda) and execute the following:</p> <pre><code>pip install pytest\npip install -e .\npytest\n</code></pre>"},{"location":"CONTRIBUTING/#useful-things-for-your-workflow-linting-and-testing","title":"Useful things for your workflow: linting and testing","text":"<p>Use <code>pre-commit</code> to lint your code and run the unit tests before pushing a new commit.</p> <p>Using <code>hatch</code>, it's simply:</p> <pre><code>hatch -e tests run pre-commit run --all-files\nhatch -e tests run test\n</code></pre> <p>Our CI/CD pipeline will also test if the documentation can be built correctly. To test it locally, please run:</p> <pre><code>hatch -e docs run mkdocs build --clean --strict\n</code></pre> <p>Without <code>hatch</code>, <code>pip</code> install those libraries first: \"mkdocs\", \"mkdocs-material\", \"mkdocstrings\", \"mkdocstrings-python\", \"mkdocs-section-index\", \"mkdocs-jupyter\", \"mkdocs-exclude\", \"markdown-exec\"</p> <p>And then:</p> <pre><code> mkdocs build --clean --strict\n</code></pre>"},{"location":"mitigation/","title":"Mitigation Methods","text":"<p>Errors may show up in various forms when trying to extract information from a quantum circuit. These include coherent and incoherent errors that effect gate execution, readout error during measurement and statistical errors.</p> <ul> <li>Incoherent errors are modelled through noisy channels, i.e. depolarizing, dephazing and erasure.</li> <li>Coherent errors are modelled as parameteric noise sampled from a distribution that shifts the operation to be performed.</li> <li>Measurement errors are introduced as bitflip operators that occur in the computational basis modelled using a confusion matrix.</li> <li>Statistical noises are introduced through finite sampling</li> </ul>"},{"location":"mitigation/#digital-errors","title":"Digital errors","text":"<p>Errors here are modelled to be executed at the end of each gate execution. The errors might be local or global. Global errors cannot be factorized as tensor products of independent channels. Implementation of digital errors is now supported on PyQ</p>"},{"location":"mitigation/#analog-errors","title":"Analog errors","text":"<p>Errors are incorporated as a part of the open system dynamics coupled with the effects of environment showing up as Krauss operators. The dynamics of an open quantum system happens through the Linbladian equation defined for markovian systems (memoryless systems). Its given by</p> \\[     \\frac{d\\rho}{dt} = L[\\rho] = -i[H,\\rho] + \\sum \\gamma_i \\bigg(L_i\\rho L_i^{\\dagger} - \\frac{1}{2} \\{L_i^{\\dagger}L_i,\\rho\\}\\bigg) \\] <p>We use qutip <code>mesolve</code> for the computation as a Pulser backend invoked for analog circuits written in Qadence. Qadence Mitigation offers a number of noise mitigation techniques to achieve better accuracy of simulation outputs. Currently supported methods mitigate primarily measurement readout errors. For analog blocks we support mitigating depolarizing and dephasing noise via Zero Noise Extrapolation.</p>"},{"location":"mitigation/incoherent_error_mitigation/","title":"Zero-noise extrapolation for analog blocks","text":"<p>Zero-noise extrapolation (ZNE) is an error mitigation technique in which the expectation value computed at different noise levels is extrapolated to the zero noise limit (ideal expectation) using a class of functions. In digital computing, this is typically implemented by \"folding\" the circuit at a local (involves inverting gates locally) or global level (involves inverting blocks of gates). This allows to artificially increase the noise levels by integer folds<sup>1</sup>. In the analog ZNE variation, analog blocks are time stretched to again artificially increase in noise<sup>1</sup>. Using ZNE on neutral atoms would require stretching the register to scale the interaction hamiltonian appropriately.</p> <pre><code>from qadence import QuantumModel, QuantumCircuit, kron, chain, AnalogRX, AnalogRZ, PI, BackendName, DiffMode, Z\nimport numpy as np\n\n\nanalog_block = chain(AnalogRX(PI / 2.0), AnalogRZ(PI))\nobservable = [Z(0) + Z(1)]\ncircuit = QuantumCircuit(2, analog_block)\nmodel_noiseless = QuantumModel(\n    circuit=circuit, observable=observable, backend=BackendName.PULSER, diff_mode=DiffMode.GPSR\n)\n</code></pre> <pre><code>noiseless_expectation = tensor([[0.3961]])\n</code></pre> <p>In analog ZNE, you can choose between two ZNE fitting methods: polynomial extrapolation and exponential decay extrapolation. This option can be specified in the mitigate function by setting <code>zne_type</code> to <code>poly</code> or <code>exp</code>, with the default being polynomial extrapolation. The <code>stretches</code> option determines which data points will be used for extrapolation. Each method requires a minimum number of data points: <code>poly</code> requires at least two, while <code>exp</code> requires at least three.</p> <pre><code>from qadence import NoiseProtocol, NoiseHandler\nfrom qadence_mitigation.protocols import Mitigations\nimport torch\n\nnoise = NoiseHandler(protocol=NoiseProtocol.ANALOG.DEPOLARIZING, options={\"noise_probs\": [0.2]})\nmodel = QuantumModel(\n    circuit=circuit, observable=observable, backend=BackendName.PULSER, diff_mode=DiffMode.GPSR\n)\n\nfor data_points, zne_type in zip([2,5], [\"poly\", \"exp\"]):\n    options = {\"stretches\": torch.linspace(1, 3, data_points), \"zne_type\": zne_type}\n    mitigate = Mitigations(protocol=Mitigations.ANALOG_ZNE, options=options)\n\n    mitigated_expectation = mitigate(model=model, noise=noise)\n</code></pre> <pre><code>noiseless_expectation with poly extrapolation and 2 data points tensor([0.3827])\nnoiseless_expectation with exp extrapolation and 5 data points tensor([0.3993])\n</code></pre>"},{"location":"mitigation/incoherent_error_mitigation/#references","title":"References","text":"<ol> <li> <p>Mitiq: What's the theory behind ZNE? \u21a9\u21a9</p> </li> </ol>"},{"location":"mitigation/readout_mitigation/","title":"Readout error mitigation","text":"<p>Readout errors are introduced during measurements in the computation basis via probabilistic bitflip operators characterized by the readout matrix (also known as confusion matrix) defined over the system of qubits of dimension \\(2^n\\times2^n\\). The complete implementation of the mitigation technique involves using the characterized readout matrix for the system of qubits \\((T)\\) and classically applying an inversion  \\((T^{\u22121})\\) to the measured probability distributions. However there are several limitations of this approach:</p> <ul> <li>The complete implementation requires \\(2^n\\) characterization experiments (probability measurements), which is not scalable.</li> <li>Classical overhead from full matrix inversion for large system of qubits is expensive</li> <li>The matrix \\(T\\) may become singular for large \\(n\\), preventing direct inversion.</li> <li>The inverse \\(T^{\u22121}\\) might not be a stochastic matrix, meaning that it can produce negative corrected probabilities.</li> <li>The correction is not rigorously justified, so we cannot be sure that we are only removing SPAM errors and not otherwise corrupting an estimated probability distribution.</li> </ul> <p>Qadence relies on the assumption of uncorrelated readout errors, this gives us:</p> \\[ T=T_1\\otimes T_2\\otimes \\dots \\otimes T_n \\] <p>for which the inversion is straightforward:</p> \\[ T^{-1}=T_1^{-1}\\otimes T_2^{-1}\\otimes \\dots \\otimes T_n^{-1} \\] <pre><code>from qadence import QuantumModel, QuantumCircuit, hamiltonian_factory, kron, H, Z, I\nfrom qadence import NoiseProtocol, NoiseHandler\n\n\n# Simple circuit and observable construction.\nblock = kron(H(0), I(1))\ncircuit = QuantumCircuit(2, block)\nn_shots = 10000\n\n# Construct a quantum model and noise\nmodel = QuantumModel(circuit=circuit)\nerror_probability = 0.2\nnoise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT,options={\"error_probability\": error_probability})\n\nnoiseless_samples = model.sample(n_shots=n_shots)\nnoisy_samples = model.sample(noise=noise, n_shots=n_shots)\n</code></pre> <pre><code>noiseless samples: [OrderedCounter({'10': 5069, '00': 4931})]\nnoisy samples: [OrderedCounter({'10': 4547, '00': 4451, '11': 517, '01': 485})]\n</code></pre> <p>Note that the noisy states have samples with the second qubit flipped. In the below protocols, we describe ways to reconstruct the noiseless distribution (untargeted mitigation). Besides this one might just be interrested in mitigating the expectation value (targeted mitigation).</p> <p>Mitigation noise</p> <p>Note it is necessary to pass the <code>noise</code> parameter for the <code>mitigation</code> function because the mitigation process sees <code>QuantumModel</code> as a black box.</p>"},{"location":"mitigation/readout_mitigation/#constrained-optimization","title":"Constrained optimization","text":"<p>However, even for a reduced \\(n\\) the forth limitation holds. This can be avoided by reformulating into a minimization problem<sup>1</sup>:</p> \\[ \\lVert Tp_{\\textrm{corr}}-p_{\\textrm{raw}}\\rVert_{2}^{2} \\] <p>subjected to physicality constraints \\(0 \\leq p_{corr}(x) \\leq 1\\) and \\(\\lVert p_{corr} \\rVert = 1\\). At this point, two methods are implemented to solve this problem. The method involves solving a constrained optimization problem and can be computationally expensive.</p> <pre><code>from qadence_mitigation.protocols import Mitigations\nfrom qadence_mitigation.types import ReadOutOptimization\n\n\n# Define the mitigation method solving the minimization problem:\noptions={\"optimization_type\": ReadOutOptimization.CONSTRAINED, \"n_shots\": n_shots}\nmitigation = Mitigations(protocol=Mitigations.READOUT, options=options)\n\n# Run noiseless, noisy and mitigated simulations.\nmitigated_samples_opt = mitigation(model=model, noise=noise)\n</code></pre> <pre><code>Optimization based mitigation: [Counter({'00': 5016, '10': 4936, '01': 26, '11': 22})]\n</code></pre>"},{"location":"mitigation/readout_mitigation/#maximum-likelihood-estimation-mle","title":"Maximum Likelihood estimation (MLE)","text":"<p>This method replaces the constraints with additional post processing for correcting probability distributions with negative entries. The runtime of the method is linear in the size of the distribution and thus is very efficient. The optimality of the solution is however not always guaranteed. The method redistributes any negative probabilities on using the inverse operation equally and can be shown to maximize the likelihood with minimal effort<sup>2</sup>.</p> <pre><code># Define the mitigation method solving the minimization problem:\noptions={\"optimization_type\": ReadOutOptimization.MLE, \"n_shots\": n_shots}\nmitigation = Mitigations(protocol=Mitigations.READOUT, options=options)\nmitigated_samples_mle = mitigation(model=model, noise=noise)\n</code></pre> <pre><code>MLE based mitigation [Counter({'00': 5009, '10': 4916, '11': 75})]\n</code></pre>"},{"location":"mitigation/readout_mitigation/#matrix-free-measurement-mitigation-mthree","title":"Matrix free measurement mitigation (MTHREE)","text":"<p>This method relies on inverting the probability distribution within a restricted subspace of measured bitstrings<sup>3</sup>. The method is better suited for computations that exceed 20 qubits where the corrected probability distribution would require a state in a unreasonably high dimensional Hilbert space. Thus, the idea here is to stick to the basis states that show up in the measurement alone. Additionally, one might want to include states that are \\(k\\) hamming distance away from it.</p> <pre><code>import numpy as np\nfrom scipy.sparse import csr_matrix\nfrom scipy.sparse.linalg import gmres\n\nn_qubits = 10\n\n# Prepare a probability distribution with sparsity\nexact_prob = np.random.rand(2 ** n_qubits)\nexact_prob[2 ** (n_qubits // 2):] = 0\nexact_prob = 0.90 * exact_prob + 0.1 * np.ones(2 ** n_qubits) / 2 ** n_qubits\nexact_prob /= sum(exact_prob)\nnp.random.shuffle(exact_prob)\n\n# Create an observed probability distribution with thresholded values\nobserved_prob = np.array(exact_prob, copy=True)\nobserved_prob[exact_prob &lt; 1 / 2 ** n_qubits] = 0\nobserved_prob /= sum(observed_prob)\n\n# Convert the observed probability distribution into a sparse matrix\ninput_csr_matrix = csr_matrix(observed_prob, shape=(1, 2**n_qubits)).T\n\n# Print the binary representation of states with nonzero probabilities\nprint({\n    bin(x)[2:].zfill(n_qubits): np.round(input_csr_matrix[x, 0], 3)\n    for x in input_csr_matrix.nonzero()[0]\n\n# Compute and display the percentage of nonzero entries\nfilling_percentage = len(input_csr_matrix.nonzero()[0]) / 2**n_qubits\n</code></pre> <pre><code>{'0000000110': 0.002, '0000111111': 0.028, '0001111100': 0.047, '0010100000': 0.006, '0011010000': 0.046, '0011010101': 0.051, '0011011010': 0.009, '0100010110': 0.049, '0100011110': 0.046, '0101000100': 0.026, '0101011010': 0.054, '0101111001': 0.025, '0110111110': 0.018, '1000110111': 0.012, '1001000101': 0.002, '1001000111': 0.032, '1001101011': 0.053, '1010001001': 0.054, '1010011011': 0.048, '1010100010': 0.025, '1011001001': 0.015, '1011010101': 0.003, '1011010110': 0.024, '1011100001': 0.032, '1011101011': 0.049, '1011111011': 0.031, '1011111101': 0.048, '1101101100': 0.043, '1110111101': 0.026, '1111010111': 0.047, '1111100001': 0.011, '1111110100': 0.038}\nFilling percentage: 0.031250 %\n</code></pre> <p>We have constructed a probability distribution over a small subspace of bitstrings, leveraging a <code>csr_matrix</code> for efficient storage and computation. Now, we apply <code>MTHREE</code> to mitigate errors in the probability distribution. Within <code>MTHREE</code>, sparsity can be further improved by incorporating the Hamming distance approach. This method considers only the noise matrix elements corresponding to quantum states within a specified Hamming distance of the correct state. This feature can be used by setting the <code>hamming_dist</code> option.</p> <pre><code>from scipy.stats import wasserstein_distance\nfrom qadence_mitigation.readout import (\n    normalized_subspace_kron,\n    mle_solve,\n    matrix_inv,\n    tensor_rank_mult\n)\n\n# Generate noise transition matrices for each qubit\nnoise_matrices = []\nfor qubit_idx in range(n_qubits):\n    transition_prob_a, transition_prob_b = np.random.rand(2) / 8\n    transition_matrix = np.array([[1 - transition_prob_a, transition_prob_a],\n                                  [transition_prob_b, 1 - transition_prob_b]]).T  # Ensure column sums to 1\n    noise_matrices.append(transition_matrix)\n\n\n\n# Compute the subspace confusion matrix using noise transition matrices. We set the hamming distance for filtering out noisy states that are far from the correct state\nsubspace_confusion_matrix = normalized_subspace_kron(noise_matrices, observed_prob.nonzero()[0], hamming_dist=1)\n\n# Apply GMRES (Generalized Minimal Residual Method) to correct the probability distribution using MTHREE. Then we apply Maximum Likelihood Estimation (MLE) to ensure the validity of the probability distribution.\ncorrected_prob_mthree_mle = mle_solve(gmres(subspace_confusion_matrix, input_csr_matrix.toarray())[0])\n\n# Next, we use tensor rank multiplication to apply the inverse noise matrices to the observed probability distribution, followed by the same MLE correction\ninverse_noise_matrices = list(map(matrix_inv, noise_matrices))\ncorrected_prob_inverse_mle = mle_solve(tensor_rank_mult(inverse_noise_matrices, observed_prob))\n\n# Finally, we compute the Wasserstein distance between the two corrected probability distributions\nwasserstein_dist = wasserstein_distance(corrected_prob_mthree_mle, corrected_prob_inverse_mle)\n</code></pre> <pre><code>Wasserstein distance between the two distributions: 8.434411543172955e-05\n</code></pre> <p>In <code>MTHREE</code>, we assume quantum circuits that exceed 20 qubits, which results in a high sparsity in the probability distribution of the output bitstrings, leading to many 0 probability bitstrings. Therefore, we use <code>Wasserstein Distance</code> instead of <code>KL divergence</code> and its derivative, <code>JS divergence</code>, as they put true values (which is 0 here) in the denominator and may diverge in such cases, whereas <code>Wasserstein Distance</code> remains stable for comparisons.</p>"},{"location":"mitigation/readout_mitigation/#majority-voting","title":"Majority Voting","text":"<p>Mitigation protocol to be used only when the circuit output has a single expected bitstring as the solution <sup>4</sup>. The method votes on the likeliness of each qubit to be a 0 or 1 assuming a tensor product structure for the output. The method is valid only when the readout errors are not correlated.</p> <pre><code>from qadence import QuantumModel, QuantumCircuit,kron, H, Z, I\nfrom qadence import NoiseHandler, NoiseProtocol\nfrom qadence_mitigation.readout import majority_vote\nimport numpy as np\n\n# Simple circuit and observable construction.\nn_qubits = 4\nblock = kron(*[I(i) for i in range(n_qubits)])\ncircuit = QuantumCircuit(n_qubits, block)\nn_shots = 1000\n\n# Construct a quantum model.\nmodel = QuantumModel(circuit=circuit)\n\n# Sampling the noisy solution\nerror_p = 0.2\nnoise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT,options={\"error_probability\": error_p})\nnoisy_samples = model.sample(noise=noise, n_shots=n_shots)[0]\n\n# Removing samples that correspond to actual solution\nnoisy_samples['0000'] = 0\n\n# Constructing the probability vector\nordered_bitstrings = [bin(k)[2:].zfill(n_qubits) for k in range(2**n_qubits)]\nobserved_prob = np.array([noisy_samples[bs] for bs in ordered_bitstrings]) / n_shots\n</code></pre> <pre><code>noisy samples: OrderedCounter({'0010': 82, '1000': 67, '0001': 63, '0100': 58, '1001': 12, '0101': 11, '0110': 9, '1010': 7, '0011': 6, '1100': 5, '0111': 1, '1011': 1, '1110': 1, '0000': 0})\nobserved probability: [0.    0.063 0.082 0.006 0.058 0.011 0.009 0.001 0.067 0.012 0.007 0.001\n 0.005 0.    0.001 0.   ]\n</code></pre> <p>We have removed the actual solution from the observed distribution and will use this as the observed probability.</p> <pre><code>noise_matrices = [np.array([[1 - error_p, error_p], [error_p, 1 - error_p]])]*n_qubits\nresult_index = majority_vote(noise_matrices, observed_prob).argmax()\n</code></pre> <pre><code>mitigated solution index: 0\n</code></pre>"},{"location":"mitigation/readout_mitigation/#model-free-mitigation","title":"Model free mitigation","text":"<p>You can perform the mitigation without a <code>quantum model</code> if you have sampled results from previous executions. This eliminates the need to reinitialize the circuit and sample again. Instead, you can directly apply the mitigation method to the existing data. To do this, you need to insert the <code>samples</code> at your <code>options</code> when initializing the <code>Mitigations</code> class.</p> <pre><code>from qadence import QuantumModel, QuantumCircuit, hamiltonian_factory, kron, H, Z, I\nfrom qadence import NoiseProtocol, NoiseHandler\nfrom qadence_mitigation.protocols import Mitigations\nfrom qadence_mitigation.types import ReadOutOptimization\n\n# Simple circuit and observable construction.\nblock = kron(H(0), I(1))\ncircuit = QuantumCircuit(2, block)\nn_shots = 10000\n\n# Construct a quantum model and noise\nmodel = QuantumModel(circuit=circuit)\nerror_probability = 0.2\nnoise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT,options={\"error_probability\": error_probability})\n\nnoiseless_samples = model.sample(n_shots=n_shots)\nnoisy_samples = model.sample(noise=noise, n_shots=n_shots)\n\n# Define the mitigation method with the sample results\noptions={\"optimization_type\": ReadOutOptimization.MLE, \"n_shots\": n_shots, \"samples\": noisy_samples}\nmitigation = Mitigations(protocol=Mitigations.READOUT, options=options)\n\n# Run noiseless, noisy and mitigated simulations.\nmitigated_samples_opt = mitigation(noise=noise)\n</code></pre> <pre><code>Noisy samples: [OrderedCounter({'00': 4562, '10': 4489, '01': 482, '11': 467})]\nMitigates samples: [Counter({'00': 5050, '10': 4950})]\n</code></pre>"},{"location":"mitigation/readout_mitigation/#twirl-mitigation","title":"Twirl mitigation","text":"<p>This protocol makes use of all possible so-called twirl operations to average out the effect of readout errors into an effective scaling. The twirl operation consists of using bit flip operators before and after the measurement <sup>5</sup>. The number of twirl operations can be reduced through random sampling with the <code>twirl_samples</code> option. The method is exact in that it requires no calibration which might be prone to modelling errors.</p> <pre><code>from qadence import NoiseHandler, NoiseProtocol\nfrom qadence.measurements import Measurements\nfrom qadence.operations import CNOT, RX, Z\nfrom qadence_mitigation.protocols import Mitigations\n\nimport torch\nfrom qadence import (\n    QuantumCircuit,\n    QuantumModel,\n    chain,\n    kron,\n)\n\nerror_probability=0.15\nn_shots=10000\nblock= chain(kron(RX(0, torch.pi / 3), RX(1, torch.pi / 6)), CNOT(0, 1))\nobservable=[3 * kron(Z(0), Z(1)) + 2 * Z(0)]\n\ncircuit = QuantumCircuit(block.n_qubits, block)\nnoise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT, options={\"error_probability\": error_probability})\ntomo_measurement = Measurements(\n    protocol=Measurements.TOMOGRAPHY,\n    options={\"n_shots\": n_shots},\n)\n\nmodel = QuantumModel(\n    circuit=circuit, observable=observable,\n)\n\nnoisy_model = QuantumModel(\n    circuit=circuit,\n    observable=observable,\n    measurement=tomo_measurement,\n    noise=noise,\n)\n\nmitigate = Mitigations(protocol=Mitigations.TWIRL)\nexpectation_mitigated = mitigate(noise=noise, model=noisy_model)\n\n\n# We set a number of qubits as the sample count. The number of twirl_samples can range from 1 to the maximum number of qubit index combinations. For example, using a higher number of samples can improve accuracy.\noptions={\"twirl_samples\": block.n_qubits}\nmitigate_sample = Mitigations(protocol=Mitigations.TWIRL, options=options)\nexpectation_mitigated_sample = mitigate_sample(noise=noise, model=noisy_model)\n</code></pre> <pre><code>noiseless expectation value tensor([[3.5910]], grad_fn=&lt;TransposeBackward0&gt;)\nnoisy expectation value tensor([[2.7170]], grad_fn=&lt;TransposeBackward0&gt;)\nexpected mitigation value tensor([3.5876])\nexpected sampled mitigation value tensor([3.5444])\n</code></pre>"},{"location":"mitigation/readout_mitigation/#references","title":"References","text":"<ol> <li> <p>Michael R. Geller and Mingyu Sun, Efficient correction of multiqubit measurement errors, (2020) \u21a9</p> </li> <li> <p>Smolin et al., Maximum Likelihood, Minimum Effort, (2011) \u21a9</p> </li> <li> <p>Gambetta et al.: Scalable mitigation of measurement errors on quantum computers \u21a9</p> </li> <li> <p>Dror Baron et al.: Maximum Likelihood Quantum Error Mitigation for Algorithms with a Single Correct Output \u21a9</p> </li> <li> <p>Kristan Temme et al. : Model-free readout-error mitigation for quantum expectation values  \u21a9</p> </li> </ol>"}]}
